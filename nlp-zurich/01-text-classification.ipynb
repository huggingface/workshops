{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b909d29-9395-4313-9e9b-73628dba7b86",
   "metadata": {},
   "source": [
    "## Main ideas\n",
    "\n",
    "* Create zero-shot baseline\n",
    "* Train XLM-R on one language and zero-shot to another\n",
    "* Create learning curves to see how much labelled data we need to beat the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377db4dc-ced6-4b81-b493-e4016fd99ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6218d6bc-d9ca-4ca2-b47d-ff3c239c644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For HF machines\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4bb95-d76c-44bd-96bc-307b32a1c325",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93553e9b-63a2-4cd7-bea3-68f0d6530988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7bebf3-d823-4f21-859b-bf28daa668fe",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "603418cd-f635-4f0b-abd5-bf46a5b63ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, load_metric, ClassLabel, Features\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dc3fc-0097-4873-887f-66d3984442ea",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8570ab71-ddf6-43b4-851d-81d4e7c7a558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_languages', 'de', 'en', 'es', 'fr', 'ja', 'zh']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"amazon_reviews_multi\"\n",
    "langs = get_dataset_config_names(dataset_name)\n",
    "langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bf4a981-f231-4f3c-a6e7-9816cc751be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/data/.cache/hf/datasets/amazon_reviews_multi/de/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc00a4ecc394d4abc1c069b1ce7ba24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_dataset = load_dataset(path=dataset_name, name=\"de\")\n",
    "german_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "747efea3-0665-4c75-a698-7f0b825a6a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'de_0203609',\n",
       " 'product_id': 'product_de_0865382',\n",
       " 'reviewer_id': 'reviewer_de_0267719',\n",
       " 'stars': 1,\n",
       " 'review_body': 'Armband ist leider nach 1 Jahr kaputt gegangen',\n",
       " 'review_title': 'Leider nach 1 Jahr kaputt',\n",
       " 'language': 'de',\n",
       " 'product_category': 'sports'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464b3c1-f453-4e02-b5d8-a7d073d16e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd4a62-0314-4681-bacb-6b10bbf93891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de_0428326</td>\n",
       "      <td>product_de_0240520</td>\n",
       "      <td>reviewer_de_0678246</td>\n",
       "      <td>4</td>\n",
       "      <td>Tisch etwas wackelig ,aber sonst zufriedenstellend</td>\n",
       "      <td>Sitzgruppe</td>\n",
       "      <td>de</td>\n",
       "      <td>lawn_and_garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de_0280733</td>\n",
       "      <td>product_de_0829653</td>\n",
       "      <td>reviewer_de_0589657</td>\n",
       "      <td>3</td>\n",
       "      <td>Ich trage sie beim Fu√üball. Sie tragen sich sehr bequem , sch√ºtzen tun sie auch , aber sie verrutschen leicht . Das war ich so von meinen vorigen nicht gewohnt</td>\n",
       "      <td>Bequem aber rutschen leicht</td>\n",
       "      <td>de</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de_0865702</td>\n",
       "      <td>product_de_0580556</td>\n",
       "      <td>reviewer_de_0290736</td>\n",
       "      <td>4</td>\n",
       "      <td>Schnelle Lieferung und gutes Aussehen. Wasserstandsanzeige unzureichend, Stift bleibt haengen.</td>\n",
       "      <td>Die Bew√§sserung der Pflanzen in den Sommermonaten k√∂nnte noch nicht getestet werfen</td>\n",
       "      <td>de</td>\n",
       "      <td>lawn_and_garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de_0324642</td>\n",
       "      <td>product_de_0658991</td>\n",
       "      <td>reviewer_de_0277583</td>\n",
       "      <td>4</td>\n",
       "      <td>Am 4 april 2018 gekauft 16 Oktober ist der radio kaputt Update Habe jetzt ein neues radio bekommen bin jetzt zufrieden hoffe das es jetzt besser geht Kabel haben eine neuere Version und das radio auch</td>\n",
       "      <td>Super</td>\n",
       "      <td>de</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de_0587772</td>\n",
       "      <td>product_de_0406394</td>\n",
       "      <td>reviewer_de_0178939</td>\n",
       "      <td>1</td>\n",
       "      <td>Zu teuer zu schlecht verarbeitet zweimal benutzt Schrott</td>\n",
       "      <td>Schrott</td>\n",
       "      <td>de</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>de_0165078</td>\n",
       "      <td>product_de_0503857</td>\n",
       "      <td>reviewer_de_0795147</td>\n",
       "      <td>1</td>\n",
       "      <td>Der Wein war ge√∂ffnet und gekippt</td>\n",
       "      <td>Schlecht</td>\n",
       "      <td>de</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>de_0299847</td>\n",
       "      <td>product_de_0455492</td>\n",
       "      <td>reviewer_de_0182181</td>\n",
       "      <td>1</td>\n",
       "      <td>Leider sticht der Punkt bei dem der Fingerabdruck in etwa ist sehr raus.</td>\n",
       "      <td>S10 nicht zu empfehlen</td>\n",
       "      <td>de</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>de_0783252</td>\n",
       "      <td>product_de_0681376</td>\n",
       "      <td>reviewer_de_0106943</td>\n",
       "      <td>5</td>\n",
       "      <td>Diese H√ºlle macht einen noch hochwertigeren Eindruck. Ist allerdings schon ein robust gebautes Teil. Sieht halt auch schon etwas martialischer aus. Das iPhone X schaut halt dann nicht mehr so filigran aus. Aber f√ºr mich genau richtig weil ich das Telefon schon sehr beanspruche und ich nicht st√§ndig darauf achten will.</td>\n",
       "      <td>Sehr Stabil</td>\n",
       "      <td>de</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>de_0910019</td>\n",
       "      <td>product_de_0347563</td>\n",
       "      <td>reviewer_de_0553149</td>\n",
       "      <td>2</td>\n",
       "      <td>nach zu sp√§ter lieferung und einigen schwierigkeiten bei der r√ºcksendung ging am ende doch alles glatt. Alles sehr kompliziert</td>\n",
       "      <td>Verz√∂gerte R√ºcksendung</td>\n",
       "      <td>de</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>de_0783482</td>\n",
       "      <td>product_de_0089593</td>\n",
       "      <td>reviewer_de_0177254</td>\n",
       "      <td>2</td>\n",
       "      <td>Leider war ich von der Rosa/Marmor Optik schon etwas entt√§uscht, die schon seeeehr gedruckt aussieht (wenn man versteht was ich damit meine) und zum anderen habe ich es auf eine Handyh√ºlle geklebt wo es sehr gut hielt, als ich aber die H√ºlle wechselte, fiel sie sofort von der neuen ab und hielt auch sonst nirgendwo mehr dran. Also leider ein Flop Produkt</td>\n",
       "      <td>H√§lt leider nur kurz und die Optik sieht sehr gedruckt aus..</td>\n",
       "      <td>de</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datasets import ClassLabel\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    \"Taken from https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb\"\n",
    "    \n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(german_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06175fe0-a101-4d7e-ba0f-8b59df5e9866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de_0203609</td>\n",
       "      <td>product_de_0865382</td>\n",
       "      <td>reviewer_de_0267719</td>\n",
       "      <td>1</td>\n",
       "      <td>Armband ist leider nach 1 Jahr kaputt gegangen</td>\n",
       "      <td>Leider nach 1 Jahr kaputt</td>\n",
       "      <td>de</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de_0559494</td>\n",
       "      <td>product_de_0678997</td>\n",
       "      <td>reviewer_de_0783625</td>\n",
       "      <td>1</td>\n",
       "      <td>In der Lieferung war nur Ein Akku!</td>\n",
       "      <td>EINS statt ZWEI Akkus!!!</td>\n",
       "      <td>de</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de_0238777</td>\n",
       "      <td>product_de_0372235</td>\n",
       "      <td>reviewer_de_0911426</td>\n",
       "      <td>1</td>\n",
       "      <td>Ein Stern, weil gar keine geht nicht. Es hande...</td>\n",
       "      <td>Achtung Abzocke</td>\n",
       "      <td>de</td>\n",
       "      <td>drugstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de_0477884</td>\n",
       "      <td>product_de_0719501</td>\n",
       "      <td>reviewer_de_0836478</td>\n",
       "      <td>1</td>\n",
       "      <td>Dachte, das w√§ren einfach etwas festere Binden...</td>\n",
       "      <td>Zu viel des Guten</td>\n",
       "      <td>de</td>\n",
       "      <td>drugstore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de_0270868</td>\n",
       "      <td>product_de_0022613</td>\n",
       "      <td>reviewer_de_0736276</td>\n",
       "      <td>1</td>\n",
       "      <td>Meine Kinder haben kaum damit gespielt und nac...</td>\n",
       "      <td>Qualit√§t sehr schlecht</td>\n",
       "      <td>de</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  de_0203609  product_de_0865382  reviewer_de_0267719      1   \n",
       "1  de_0559494  product_de_0678997  reviewer_de_0783625      1   \n",
       "2  de_0238777  product_de_0372235  reviewer_de_0911426      1   \n",
       "3  de_0477884  product_de_0719501  reviewer_de_0836478      1   \n",
       "4  de_0270868  product_de_0022613  reviewer_de_0736276      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0     Armband ist leider nach 1 Jahr kaputt gegangen   \n",
       "1                 In der Lieferung war nur Ein Akku!   \n",
       "2  Ein Stern, weil gar keine geht nicht. Es hande...   \n",
       "3  Dachte, das w√§ren einfach etwas festere Binden...   \n",
       "4  Meine Kinder haben kaum damit gespielt und nac...   \n",
       "\n",
       "                review_title language  product_category  \n",
       "0  Leider nach 1 Jahr kaputt       de            sports  \n",
       "1   EINS statt ZWEI Akkus!!!       de  home_improvement  \n",
       "2            Achtung Abzocke       de         drugstore  \n",
       "3          Zu viel des Guten       de         drugstore  \n",
       "4     Qualit√§t sehr schlecht       de               toy  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_dataset.set_format(\"pandas\")\n",
    "german_df = german_dataset[\"train\"][:]\n",
    "german_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28dd3589-453b-4b5e-b3a6-e6596a951623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119737</th>\n",
       "      <td>de_0970901</td>\n",
       "      <td>product_de_0712478</td>\n",
       "      <td>reviewer_de_0308094</td>\n",
       "      <td>3</td>\n",
       "      <td>Ist ok ...blondierung quillt schnell auf</td>\n",
       "      <td>Ok</td>\n",
       "      <td>de</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72272</th>\n",
       "      <td>de_0042217</td>\n",
       "      <td>product_de_0734686</td>\n",
       "      <td>reviewer_de_0904358</td>\n",
       "      <td>2</td>\n",
       "      <td>Kein typischer Geruch oder Geschmack von einem Ghee! Ich w√ºrde es nicht wieder kaufen oder weiter empfehlen. Konkurrenz Produkt fand ich besser.</td>\n",
       "      <td>Kein typischer Geruch oder Geschmack von einem Ghee !</td>\n",
       "      <td>de</td>\n",
       "      <td>grocery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158154</th>\n",
       "      <td>de_0278932</td>\n",
       "      <td>product_de_0388890</td>\n",
       "      <td>reviewer_de_0940030</td>\n",
       "      <td>4</td>\n",
       "      <td>Dieses Buch hat mir sehr geholfen mit dem ersten Schlupf und der weiteren Aufzucht. Kann ich nur weiter empfehlen.</td>\n",
       "      <td>Sehr hilfreich</td>\n",
       "      <td>de</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65426</th>\n",
       "      <td>de_0737352</td>\n",
       "      <td>product_de_0560586</td>\n",
       "      <td>reviewer_de_0632435</td>\n",
       "      <td>2</td>\n",
       "      <td>super Schale, wundersch√∂n, gutes Produkt ABER Der Saugnapf geht von der Schale runter, da die Ma√üe des Saugnapf Ringes nicht passen. Man muss aufpassen dass man den nicht dauernd neu aufsetzen muss.</td>\n",
       "      <td>der Saugnapf h√§lt nicht</td>\n",
       "      <td>de</td>\n",
       "      <td>baby_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30074</th>\n",
       "      <td>de_0455430</td>\n",
       "      <td>product_de_0375951</td>\n",
       "      <td>reviewer_de_0482228</td>\n",
       "      <td>1</td>\n",
       "      <td>Artikel ist niemals angekommen, habe ihn aber bezahlt! Und dann steht noch dort ich h√§tte unterschrieben, als er angeblich angekommen sei! null Sterne! Unglaublich üòí</td>\n",
       "      <td>Artikel ist niemals angekommen!!</td>\n",
       "      <td>de</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23677</th>\n",
       "      <td>de_0007108</td>\n",
       "      <td>product_de_0230566</td>\n",
       "      <td>reviewer_de_0672101</td>\n",
       "      <td>1</td>\n",
       "      <td>habe das headset seit 2 jahren es ist einfach ein rauschen gekommen wenn ich rede einfach so man kann mich garnicht mehr verstehen</td>\n",
       "      <td>Mikrofon einfach Kaputt gegen ein rausch wenn ich rede</td>\n",
       "      <td>de</td>\n",
       "      <td>video_games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134858</th>\n",
       "      <td>de_0990930</td>\n",
       "      <td>product_de_0723421</td>\n",
       "      <td>reviewer_de_0677949</td>\n",
       "      <td>4</td>\n",
       "      <td>War mein erster Versuch mit einem Seifenst√ºck als Shampoo und ist etwas gew√∂hnungsbef√ºrftig. Hatte am Anfang das Gef√ºhl, dass die Haare nicht richtig sauber werden aber eine Freundin hat mir dann eine andere Methode zum Auftragen gezeigt mit der es ganz gut klappt. Besser f√ºr die Umwelt ist es aber allemals!</td>\n",
       "      <td>Ein Versuch wert</td>\n",
       "      <td>de</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176418</th>\n",
       "      <td>de_0902392</td>\n",
       "      <td>product_de_0985447</td>\n",
       "      <td>reviewer_de_0695647</td>\n",
       "      <td>5</td>\n",
       "      <td>Immer wieder gern zu spielen, viel Spa√ü und auch sehr spannend. Vorsicht: macht s√ºchtig</td>\n",
       "      <td>Spiel</td>\n",
       "      <td>de</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132467</th>\n",
       "      <td>de_0537198</td>\n",
       "      <td>product_de_0386242</td>\n",
       "      <td>reviewer_de_0590416</td>\n",
       "      <td>4</td>\n",
       "      <td>Die Werkzeuge sind von guter Qualit√§t, sie machen absolut das, was sie sollen. Allerdings war ein Schraubendreher durch den Versand leicht verbogen, daher nur 4 von 5 Sternen.</td>\n",
       "      <td>Tolles Set, Werkzeuge guter Qualit√§t</td>\n",
       "      <td>de</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>de_0626877</td>\n",
       "      <td>product_de_0410155</td>\n",
       "      <td>reviewer_de_0752644</td>\n",
       "      <td>1</td>\n",
       "      <td>Sehr entt√§uschend! Neu? Verdreckt, kaputt und stinkend kam die K√ºhlbox! Mehr als schade! Geht sofort zur√ºck, daf√ºr m√ºsste ich es noch nicht mal aus dem Karton nehmen! Der Stern w√ºrde nur gegeben, weil diese Bewertung ohne nicht geht!</td>\n",
       "      <td>Sauer!!</td>\n",
       "      <td>de</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = german_df.sample(n=10, random_state=42)\n",
    "display(HTML(sample.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55da43bd-e114-43d5-b762-7eec4567b771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home                        26063\n",
       "wireless                    19964\n",
       "sports                      13748\n",
       "home_improvement            12408\n",
       "apparel                     10178\n",
       "toy                          9781\n",
       "pc                           8577\n",
       "drugstore                    8075\n",
       "lawn_and_garden              7426\n",
       "beauty                       7162\n",
       "electronics                  7114\n",
       "other                        6460\n",
       "furniture                    6334\n",
       "kitchen                      5787\n",
       "automotive                   5321\n",
       "pet_products                 5028\n",
       "book                         4927\n",
       "office_product               4343\n",
       "baby_product                 4070\n",
       "shoes                        3568\n",
       "luggage                      3256\n",
       "digital_video_download       2970\n",
       "personal_care_appliances     2836\n",
       "grocery                      2737\n",
       "digital_ebook_purchase       2720\n",
       "jewelry                      2380\n",
       "camera                       1906\n",
       "watch                        1706\n",
       "video_games                  1219\n",
       "industrial_supplies          1092\n",
       "musical_instruments           844\n",
       "Name: product_category, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_df[\"product_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cf02584-abc2-4a43-9b2f-5a003d9f51de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40000\n",
       "2    40000\n",
       "3    40000\n",
       "4    40000\n",
       "5    40000\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_df[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d68d44a1-9dce-4f80-9184-dab3c4e4a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2420dd-b6ca-4c41-811d-e4922e400339",
   "metadata": {},
   "source": [
    "## Remap the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e24196e-dc05-4b8f-bf30-55519305e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_dataset = german_dataset.rename_column(\"stars\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0730fcd9-f68c-44e6-8b41-932921a339c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {idx+1:idx for idx in range(5)}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ccc2875-f937-49c5-b483-93fa5589c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(examples):\n",
    "    return {\"labels\": label_mapping[examples[\"labels\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f4f857d-1cd0-4435-bd5e-c4cc6e072dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70712f2c40444fb08b7bd0bd08b5c2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdeb6f60b3ed4fcf8f8f2a64b01b6216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2248756ef6b04ff9ba4f340bcfe843f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "german_dataset = german_dataset.map(map_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d41cad-1a3c-4f7f-86df-8327aff415ea",
   "metadata": {},
   "source": [
    "## Zero-shot baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0996437f-0004-49e8-aff7-0aac54824c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4ecf890-4c7a-4aac-9355-4cd8af1c997c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Ich liebe dieses Buch!',\n",
       " 'labels': [3, 4, 0, 2, 1],\n",
       " 'scores': [0.2328941971063614,\n",
       "  0.2296580672264099,\n",
       "  0.21016642451286316,\n",
       "  0.19636668264865875,\n",
       "  0.13091468811035156]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classifier(\"Ich liebe dieses Buch!\", candidate_labels=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a3718b4-bad5-4e84-a187-89789e1d5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zeroshot_preds(examples):\n",
    "    preds = zeroshot_classifier(examples[\"review_body\"], candidate_labels=[0,1,2,3,4])\n",
    "    return {\"zeroshot_prediction\": preds[\"labels\"][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66bf5aaa-10c8-49d6-8dc2-b57f169cdd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083806ed4c354d05a8ad0091a457e332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/miniconda3/envs/hf/lib/python3.9/site-packages/transformers/pipelines/base.py:899: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "german_test_dataset = german_dataset[\"test\"].map(compute_zeroshot_preds)\n",
    "german_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebadb830-788f-469e-9a4c-d6cb5d506ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 4, 0, 1, 0, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_test_dataset[\"zeroshot_prediction\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27a3fb27-96d0-417b-8695-677e81b82c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_test_dataset[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40b4e82a-ec42-41dc-8452-b8f92c74e49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2926"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(german_test_dataset[\"labels\"], german_test_dataset[\"zeroshot_prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67116204-d608-4c24-aa72-9f8d169987f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2de857a8-ac62-4f0b-8376-1194718014a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efffa20f-2983-4e86-afa3-9bf8a8d44aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(examples):\n",
    "    return tokenizer(examples[\"review_body\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0a246bc-9df9-4f80-9d68-b45a50c4ee66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8d2f00f90444aa9d370a69a06ed098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc373155ecd4ddeb95bc8706890bff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b732e369be68402989b129d49e0c3c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = german_dataset.map(tokenize_reviews, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab0ef8f-95e8-4574-9a6e-4c5d9e638ca2",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9765ff12-5395-446e-ac5a-6929e12098ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 5\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aacd06-57a7-460f-82ab-372f789be822",
   "metadata": {},
   "source": [
    "## Create metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b605f30b-9fba-48dd-8d26-b96c09d1004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"MAE\": mean_absolute_error(labels, predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c48c2-e7ee-4e0f-a31c-70a23c800530",
   "metadata": {},
   "source": [
    "## Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0cddcb1-6695-4537-ab7d-be4798458b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b2d9f66-525e-4960-9860-1a8e7fb6f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 16\n",
    "num_train_epochs = 3\n",
    "\n",
    "num_train_samples = 500\n",
    "train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(num_train_samples))\n",
    "logging_steps = len(train_dataset) // (batch_size * num_train_epochs)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-marc-{num_train_samples}-samples\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d45d568c-c230-41c2-b73b-a1da577c9e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis/git/workshops/nlp-zurich/xlm-roberta-base-finetuned-marc-500-samples is already a clone of https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5514485-36a4-436f-901d-cddf65e7383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6235263347625732,\n",
       " 'eval_MAE': 2.0,\n",
       " 'eval_runtime': 17.1764,\n",
       " 'eval_samples_per_second': 291.098,\n",
       " 'eval_steps_per_second': 18.223}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6b1f0d7-e1a1-4658-813a-18f25d2aea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running training *****\n",
      "  Num examples = 500\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 03:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.614900</td>\n",
       "      <td>1.603234</td>\n",
       "      <td>1.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.596700</td>\n",
       "      <td>1.589962</td>\n",
       "      <td>1.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.567500</td>\n",
       "      <td>1.485550</td>\n",
       "      <td>1.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.438200</td>\n",
       "      <td>1.366122</td>\n",
       "      <td>0.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.300900</td>\n",
       "      <td>1.327512</td>\n",
       "      <td>0.874600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples/checkpoint-32\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-32/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-32/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-32/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-32/special_tokens_map.json\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples/checkpoint-64\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-64/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-64/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-64/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-64/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples/checkpoint-96\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-96/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-96/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-96/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-96/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples/checkpoint-128\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-128/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-128/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-128/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-128/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples/checkpoint-160\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-160/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-160/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-160/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/checkpoint-160/special_tokens_map.json\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=1.505726170539856, metrics={'train_runtime': 219.5709, 'train_samples_per_second': 11.386, 'train_steps_per_second': 0.729, 'total_flos': 232485434971824.0, 'train_loss': 1.505726170539856, 'epoch': 5.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48f9dae8-894c-4427-b2fd-8ac4a45d168b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to xlm-roberta-base-finetuned-marc-500-samples\n",
      "Configuration saved in xlm-roberta-base-finetuned-marc-500-samples/config.json\n",
      "Model weights saved in xlm-roberta-base-finetuned-marc-500-samples/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-base-finetuned-marc-500-samples/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-base-finetuned-marc-500-samples/special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94d7835e3d343298be1f9ebdce89cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/1.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0901c06cb4fc41718634ca9c25f7e98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Oct12_16-57-03_vorace/events.out.tfevents.1634050856.vorace: 100%|##########| 8.01k/8.01k [00‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at cc8d97f269f272d245b499730226a5e45c790897 but expected 1ad385c8a07abc1ca653d5ac11b1e91586cb4163        \n",
      "To https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at cc8d97f269f272d245b499730226a5e45c790897 but expected 1ad385c8a07abc1ca653d5ac11b1e91586cb4163        \nTo https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.9/site-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mgit_push\u001b[0;34m(self, upstream, blocking)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m                         raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    969\u001b[0m                             \u001b[0mreturn_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3637600/729006586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   2667\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m         \u001b[0mgit_head_commit_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2670\u001b[0m         \u001b[0;31m# push separately the model card to be independant from the rest of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.9/site-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_lfs_track\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_commit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         return self.git_push(\n\u001b[0m\u001b[1;32m   1195\u001b[0m             \u001b[0mupstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"origin {self.current_branch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/hf/lib/python3.9/site-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mgit_push\u001b[0;34m(self, upstream, blocking)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at cc8d97f269f272d245b499730226a5e45c790897 but expected 1ad385c8a07abc1ca653d5ac11b1e91586cb4163        \nTo https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/lewtun/xlm-roberta-base-finetuned-marc-500-samples'\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59472032-1c4a-400c-9eb4-324c40515c0c",
   "metadata": {},
   "source": [
    "## Zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77c44999-5a1d-4d34-8a72-81936158bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_corpus(lang):\n",
    "    dataset = load_dataset(dataset_name, lang, split=\"test\")\n",
    "    dataset = dataset.rename_column(\"stars\", \"labels\")\n",
    "    dataset = dataset.map(map_labels)\n",
    "    tokenized_dataset = dataset.map(tokenize_reviews, batched=True)\n",
    "    preds = trainer.evaluate(eval_dataset=tokenized_dataset)\n",
    "    return {\"MAE\": preds[\"eval_MAE\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "172ae1fb-e5a3-437d-bfc1-752837b010fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/data/.cache/hf/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7d25a3400443de8193aab010e6ec09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03f65aa042b4114b86ac04239b80c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='626' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.874}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_corpus(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4be0db14-2abc-4597-ade1-a27196a95e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/data/.cache/hf/datasets/amazon_reviews_multi/fr/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0b09fe2ab34526b58a4124a2cc63b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544f7f29b8b34742b4e794b448245888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: reviewer_id, product_id, review_title, review_body, review_id, product_category, language.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.8742}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_corpus(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50100e5f-2344-4baf-9a9d-acf514693651",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=trainer.model, tokenizer=trainer.tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2582a5b7-0fc1-4b48-9e10-8a8b4ac76af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_3', 'score': 0.30068162083625793}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I love this book!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f80954b-5776-486a-906f-89cf9b1e1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.372832715511322}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Ich hasse dieses Buch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19b447b9-2efd-40a0-ac4b-001b2026bf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_3', 'score': 0.2572416365146637}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"J'adore ce livre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428f746-d2c2-43b3-ac9d-d5b3a71baf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
